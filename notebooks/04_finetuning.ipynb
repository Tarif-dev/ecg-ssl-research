{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0ed584",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Notebook 04: Few-Shot Fine-tuning & Evaluation (Stage 2)\n",
    "\n",
    "**Goal:** Use the pre-trained encoder to classify Normal vs Arrhythmia with very few labeled examples.\n",
    "\n",
    "**Key experiment:** How many labels do we need?\n",
    "- **10-shot:** Only 10 Normal + 10 Arrhythmia examples\n",
    "- **50-shot:** 50 per class\n",
    "- **100-shot:** 100 per class\n",
    "- **Baseline:** Training from scratch (no pre-training) for comparison\n",
    "\n",
    "**Expected result:** Pre-trained model should achieve >90% accuracy with just 100 labels, while training from scratch gets <70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Setup\n",
    "# ============================================================\n",
    "!pip install -q wfdb numpy scipy matplotlib scikit-learn pyyaml tqdm wandb seaborn\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_DIR = '/content/drive/MyDrive/ecg_ssl_research'\n",
    "PROCESSED_DIR = os.path.join(PROJECT_DIR, 'data', 'processed')\n",
    "PRETRAIN_DIR = os.path.join(PROJECT_DIR, 'experiments', 'pretraining')\n",
    "FINETUNE_DIR = os.path.join(PROJECT_DIR, 'experiments', 'finetuning')\n",
    "os.makedirs(FINETUNE_DIR, exist_ok=True)\n",
    "\n",
    "REPO_DIR = '/content/ecg-ssl-research'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    REPO_URL = \"https://github.com/Tarif-dev/ecg-ssl-research.git\"  # <-- CHANGE THIS\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "from src.utils import set_seed, get_device, load_config, count_parameters\n",
    "from src.models import ECGMaskedAutoencoder, ECGClassifier\n",
    "from src.data_loader import create_finetune_dataloaders\n",
    "from src.training import (\n",
    "    finetune, evaluate, compute_metrics,\n",
    "    plot_training_history,\n",
    ")\n",
    "\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "print(\"âœ“ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aee340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Load pre-trained model & labeled data\n",
    "# ============================================================\n",
    "\n",
    "# Load configs\n",
    "pretrain_config = load_config(os.path.join(REPO_DIR, 'configs', 'pretrain_config.yaml'))\n",
    "finetune_config = load_config(os.path.join(REPO_DIR, 'configs', 'finetune_config.yaml'))\n",
    "\n",
    "# Recreate MAE architecture and load pre-trained weights\n",
    "mae_model = ECGMaskedAutoencoder(\n",
    "    patch_size=pretrain_config['model']['patch_size'],\n",
    "    embed_dim=pretrain_config['model']['embed_dim'],\n",
    "    depth=pretrain_config['model']['depth'],\n",
    "    num_heads=pretrain_config['model']['num_heads'],\n",
    "    mlp_ratio=pretrain_config['model']['mlp_ratio'],\n",
    "    dropout=pretrain_config['model']['dropout'],\n",
    "    decoder_depth=pretrain_config['model']['decoder_depth'],\n",
    "    mask_ratio=pretrain_config['model']['mask_ratio'],\n",
    ")\n",
    "\n",
    "# Load pre-trained weights (from Notebook 03)\n",
    "pretrain_ckpt = torch.load(\n",
    "    os.path.join(PRETRAIN_DIR, 'best_model.pt'),\n",
    "    map_location='cpu', weights_only=False\n",
    ")\n",
    "mae_model.load_state_dict(pretrain_ckpt['model_state_dict'])\n",
    "print(f\"âœ“ Pre-trained model loaded (epoch {pretrain_ckpt['epoch']}, \"\n",
    "      f\"loss {pretrain_ckpt['train_loss']:.4f})\")\n",
    "\n",
    "# Load labeled beats\n",
    "beats = np.load(os.path.join(PROCESSED_DIR, 'finetune_beats.npy'))\n",
    "labels = np.load(os.path.join(PROCESSED_DIR, 'finetune_labels.npy'))\n",
    "print(f\"âœ“ Labeled data: {beats.shape[0]:,} beats\")\n",
    "print(f\"  Normal: {(labels==0).sum():,}, Arrhythmia: {(labels==1).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Fine-tune with 100 labels (main experiment)\n",
    "# ============================================================\n",
    "\n",
    "N_SHOT = 100  # Try 10, 50, 100, or 1000\n",
    "SEED = 42\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# Create data splits (100 Normal + 100 Arrhythmia for training)\n",
    "loaders = create_finetune_dataloaders(\n",
    "    beats, labels, n_shot=N_SHOT,\n",
    "    batch_size=finetune_config['training']['batch_size'],\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Create classifier from pre-trained encoder\n",
    "classifier = ECGClassifier.from_pretrained(\n",
    "    mae_model,\n",
    "    num_classes=finetune_config['model']['num_classes'],\n",
    "    freeze_layers=finetune_config['model']['freeze_layers'],\n",
    "    dropout=finetune_config['model']['dropout'],\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nClassifier Architecture:\")\n",
    "count_parameters(classifier)\n",
    "\n",
    "# Fine-tune!\n",
    "save_dir = os.path.join(FINETUNE_DIR, f'{N_SHOT}shot_seed{SEED}')\n",
    "classifier, ft_history = finetune(\n",
    "    model=classifier,\n",
    "    train_loader=loaders['train'],\n",
    "    val_loader=loaders['val'],\n",
    "    config=finetune_config,\n",
    "    device=device,\n",
    "    save_dir=save_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 4: Evaluate on test set\n",
    "# ============================================================\n",
    "import seaborn as sns\n",
    "\n",
    "# Load best model\n",
    "best_ckpt = torch.load(\n",
    "    os.path.join(save_dir, 'best_model.pt'),\n",
    "    map_location=device, weights_only=False\n",
    ")\n",
    "classifier.load_state_dict(best_ckpt['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {best_ckpt['epoch']} (Val F1: {best_ckpt['val_f1']:.3f})\\n\")\n",
    "\n",
    "# Evaluate on held-out test set\n",
    "test_results = evaluate(classifier, loaders['test'], device)\n",
    "metrics = compute_metrics(test_results, class_names=['Normal', 'Arrhythmia'])\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"  TEST RESULTS ({N_SHOT}-shot, pre-trained)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Accuracy: {metrics['accuracy']:.3f}\")\n",
    "print(f\"  Macro F1: {metrics['macro_f1']:.3f}\")\n",
    "print(f\"  AUC-ROC:  {metrics['auc_roc']:.3f}\")\n",
    "print(f\"\\n{metrics['classification_report']}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Normal', 'Arrhythmia'],\n",
    "            yticklabels=['Normal', 'Arrhythmia'], ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title(f'Confusion Matrix ({N_SHOT}-shot)')\n",
    "\n",
    "# Plot training curves\n",
    "keys_to_plot = {k: v for k, v in ft_history.items() if any(x is not None for x in v)}\n",
    "for key, vals in keys_to_plot.items():\n",
    "    axes[1].plot(vals, label=key.replace('_', ' ').title())\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_title('Fine-tuning History')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROJECT_DIR, f'results_{N_SHOT}shot.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b063e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 5: Baseline comparison â€” Train from SCRATCH (no pre-training)\n",
    "# ============================================================\n",
    "# This proves that pre-training helps!\n",
    "\n",
    "from src.models import PatchEmbedding, ECGTransformerEncoder, ClassificationHead\n",
    "import torch.nn as nn\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "class BaselineClassifier(nn.Module):\n",
    "    \"\"\"Same architecture but randomly initialized (no pre-training).\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(\n",
    "            patch_size=pretrain_config['model']['patch_size'],\n",
    "            embed_dim=pretrain_config['model']['embed_dim'],\n",
    "        )\n",
    "        self.encoder = ECGTransformerEncoder(\n",
    "            embed_dim=pretrain_config['model']['embed_dim'],\n",
    "            depth=pretrain_config['model']['depth'],\n",
    "            num_heads=pretrain_config['model']['num_heads'],\n",
    "        )\n",
    "        self.classifier = ClassificationHead(\n",
    "            embed_dim=pretrain_config['model']['embed_dim'],\n",
    "            num_classes=2, dropout=0.5,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = self.encoder(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Train baseline (same data, same hyperparams, NO pre-training)\n",
    "baseline = BaselineClassifier().to(device)\n",
    "print(\"Baseline (random init, no pre-training):\")\n",
    "count_parameters(baseline)\n",
    "\n",
    "baseline_save = os.path.join(FINETUNE_DIR, f'baseline_{N_SHOT}shot')\n",
    "baseline, baseline_hist = finetune(\n",
    "    baseline, loaders['train'], loaders['val'],\n",
    "    finetune_config, device, baseline_save,\n",
    ")\n",
    "\n",
    "# Evaluate baseline\n",
    "best_base = torch.load(os.path.join(baseline_save, 'best_model.pt'),\n",
    "                       map_location=device, weights_only=False)\n",
    "baseline.load_state_dict(best_base['model_state_dict'])\n",
    "base_results = evaluate(baseline, loaders['test'], device)\n",
    "base_metrics = compute_metrics(base_results, ['Normal', 'Arrhythmia'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"  COMPARISON ({N_SHOT}-shot)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Metric':<15} {'Pre-trained':>12} {'From Scratch':>12} {'Î”':>8}\")\n",
    "print(f\"{'-'*47}\")\n",
    "for key in ['accuracy', 'macro_f1', 'auc_roc']:\n",
    "    pre = metrics[key]\n",
    "    base = base_metrics[key]\n",
    "    if pre is not None and base is not None:\n",
    "        delta = pre - base\n",
    "        print(f\"{key:<15} {pre:>12.3f} {base:>12.3f} {delta:>+8.3f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Pre-training improvement: \"\n",
    "      f\"+{(metrics['macro_f1']-base_metrics['macro_f1'])*100:.1f}% F1 score!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 6: Few-shot ablation study (10 vs 50 vs 100 vs 1000)\n",
    "# ============================================================\n",
    "# Run this cell to generate the main result table for your paper\n",
    "# NOTE: This takes a while â€” runs multiple experiments\n",
    "\n",
    "from src.training import run_few_shot_experiment\n",
    "\n",
    "# Reload the pre-trained MAE (clean copy)\n",
    "mae_clean = ECGMaskedAutoencoder(\n",
    "    patch_size=pretrain_config['model']['patch_size'],\n",
    "    embed_dim=pretrain_config['model']['embed_dim'],\n",
    "    depth=pretrain_config['model']['depth'],\n",
    "    num_heads=pretrain_config['model']['num_heads'],\n",
    "    mlp_ratio=pretrain_config['model']['mlp_ratio'],\n",
    "    dropout=pretrain_config['model']['dropout'],\n",
    "    decoder_depth=pretrain_config['model']['decoder_depth'],\n",
    "    mask_ratio=pretrain_config['model']['mask_ratio'],\n",
    ")\n",
    "mae_clean.load_state_dict(pretrain_ckpt['model_state_dict'])\n",
    "\n",
    "# Run few-shot experiments\n",
    "results = run_few_shot_experiment(\n",
    "    mae_model=mae_clean,\n",
    "    segments=beats,\n",
    "    labels=labels,\n",
    "    n_shots=finetune_config['few_shot']['n_shots'],\n",
    "    seeds=finetune_config['few_shot']['seeds'][:3],  # Use 3 seeds to save time\n",
    "    config=finetune_config,\n",
    "    device=device,\n",
    "    save_dir=os.path.join(FINETUNE_DIR, 'few_shot_study'),\n",
    ")\n",
    "\n",
    "# Pretty print results table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  FEW-SHOT RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'N-shot':<10} {'Accuracy':>15} {'Macro F1':>15} {'AUC-ROC':>15}\")\n",
    "print(\"-\"*55)\n",
    "for n_shot, m in sorted(results.items()):\n",
    "    print(f\"{n_shot:<10} \"\n",
    "          f\"{m['accuracy']['mean']:.3f}Â±{m['accuracy']['std']:.3f}   \"\n",
    "          f\"{m['macro_f1']['mean']:.3f}Â±{m['macro_f1']['std']:.3f}   \"\n",
    "          f\"{m['auc_roc']['mean']:.3f}Â±{m['auc_roc']['std']:.3f}\")\n",
    "\n",
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "shots = sorted(results.keys())\n",
    "f1_means = [results[s]['macro_f1']['mean'] for s in shots]\n",
    "f1_stds = [results[s]['macro_f1']['std'] for s in shots]\n",
    "\n",
    "bars = ax.bar([str(s) for s in shots], f1_means, yerr=f1_stds,\n",
    "              color='steelblue', capsize=5, edgecolor='navy', alpha=0.8)\n",
    "ax.set_xlabel('Number of Labels per Class', fontsize=12)\n",
    "ax.set_ylabel('Macro F1 Score', fontsize=12)\n",
    "ax.set_title('Few-Shot Performance (Pre-trained Transformer)', fontsize=14)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.axhline(y=0.9, color='red', linestyle='--', alpha=0.5, label='Target: 90%')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, mean in zip(bars, f1_means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n",
    "            f'{mean:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROJECT_DIR, 'few_shot_results.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ All experiments complete! Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
