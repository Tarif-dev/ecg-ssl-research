{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e14055e",
   "metadata": {},
   "source": [
    "# ðŸ§  Notebook 03: Self-Supervised Pre-training (Stage 1)\n",
    "\n",
    "**Goal:** Train the Masked Autoencoder to reconstruct masked ECG patches â€” learning general cardiac signal representations without any labels.\n",
    "\n",
    "**What happens:**\n",
    "1. Load 100,000+ unlabeled ECG segments (from Notebook 02)\n",
    "2. Mask 75% of each signal randomly\n",
    "3. Train a Transformer to reconstruct the masked regions\n",
    "4. Save the pre-trained encoder weights for Stage 2\n",
    "\n",
    "**Expected time:** ~1â€“2 hours on Colab T4 GPU (100 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Setup\n",
    "# ============================================================\n",
    "!pip install -q wfdb numpy scipy matplotlib scikit-learn pyyaml tqdm wandb\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "PROJECT_DIR = '/content/drive/MyDrive/ecg_ssl_research'\n",
    "PROCESSED_DIR = os.path.join(PROJECT_DIR, 'data', 'processed')\n",
    "PRETRAIN_SAVE_DIR = os.path.join(PROJECT_DIR, 'experiments', 'pretraining')\n",
    "os.makedirs(PRETRAIN_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "REPO_DIR = '/content/ecg-ssl-research'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    REPO_URL = \"https://github.com/Tarif-dev/ecg-ssl-research.git\"  # <-- CHANGE THIS\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "from src.utils import set_seed, get_device, load_config, count_parameters\n",
    "from src.models import ECGMaskedAutoencoder\n",
    "from src.data_loader import create_pretrain_dataloader\n",
    "from src.training import pretrain, visualize_reconstruction, plot_training_history\n",
    "\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "print(\"âœ“ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Load processed data & create DataLoader\n",
    "# ============================================================\n",
    "\n",
    "# Load pre-training segments (from Notebook 02)\n",
    "segments_path = os.path.join(PROCESSED_DIR, 'pretrain_segments.npy')\n",
    "segments = np.load(segments_path)\n",
    "print(f\"âœ“ Loaded segments: {segments.shape}\")\n",
    "print(f\"  {len(segments):,} segments Ã— {segments.shape[1]} samples\")\n",
    "\n",
    "# Load config\n",
    "config = load_config(os.path.join(REPO_DIR, 'configs', 'pretrain_config.yaml'))\n",
    "\n",
    "# Split: 90% train, 10% validation\n",
    "n_val = int(len(segments) * 0.1)\n",
    "val_segments = segments[:n_val]\n",
    "train_segments = segments[n_val:]\n",
    "\n",
    "print(f\"  Train: {len(train_segments):,} segments\")\n",
    "print(f\"  Val:   {len(val_segments):,} segments\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = create_pretrain_dataloader(\n",
    "    train_segments,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    num_workers=config['training']['num_workers'],\n",
    "    augment=True,\n",
    ")\n",
    "val_loader = create_pretrain_dataloader(\n",
    "    val_segments,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    num_workers=config['training']['num_workers'],\n",
    "    augment=False,\n",
    ")\n",
    "\n",
    "# Quick sanity check\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nâœ“ Sample batch shape: {sample_batch[0].shape}\")  # [B, 3600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ad18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Create model & start pre-training\n",
    "# ============================================================\n",
    "# This is the main training cell â€” takes ~1-2 hours on T4 GPU\n",
    "\n",
    "# Create Masked Autoencoder model\n",
    "model = ECGMaskedAutoencoder(\n",
    "    patch_size=config['model']['patch_size'],\n",
    "    embed_dim=config['model']['embed_dim'],\n",
    "    depth=config['model']['depth'],\n",
    "    num_heads=config['model']['num_heads'],\n",
    "    mlp_ratio=config['model']['mlp_ratio'],\n",
    "    dropout=config['model']['dropout'],\n",
    "    decoder_depth=config['model']['decoder_depth'],\n",
    "    mask_ratio=config['model']['mask_ratio'],\n",
    ").to(device)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(f\"  Patch size: {config['model']['patch_size']}\")\n",
    "print(f\"  Mask ratio: {config['model']['mask_ratio']} (75%)\")\n",
    "print(f\"  Encoder: {config['model']['depth']} layers, \"\n",
    "      f\"{config['model']['num_heads']} heads, \"\n",
    "      f\"{config['model']['embed_dim']} dim\")\n",
    "print(f\"  Decoder: {config['model']['decoder_depth']} layers\")\n",
    "count_parameters(model)\n",
    "\n",
    "# Quick forward pass test\n",
    "with torch.no_grad():\n",
    "    test_input = sample_batch[0][:4].to(device)\n",
    "    test_pred, test_mask = model(test_input)\n",
    "    print(f\"\\nâœ“ Forward pass test:\")\n",
    "    print(f\"  Input:  {test_input.shape}\")\n",
    "    print(f\"  Output: {test_pred.shape}\")\n",
    "    print(f\"  Mask:   {test_mask.shape} (mean={test_mask.mean():.2f})\")\n",
    "\n",
    "        props = torch.cuda.get_device_properties(0)\n",
    "        gpu_mem = getattr(props, 'total_memory', getattr(props, 'total_mem', 0)) / 1e9\n",
    "\n",
    "# âš¡ Run pre-training!\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting pre-training... (this takes ~1-2 hours on T4)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model, history = pretrain(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    save_dir=PRETRAIN_SAVE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 4: Visualize results\n",
    "# ============================================================\n",
    "\n",
    "# Plot training curves\n",
    "plot_training_history(\n",
    "    history,\n",
    "    title=\"Pre-training History\",\n",
    "    save_path=os.path.join(PROJECT_DIR, 'pretrain_curves.png')\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()\n",
    "\n",
    "# Visualize reconstruction quality on random samples\n",
    "print(\"\\nReconstruction Examples:\")\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(len(val_segments))\n",
    "    fig = visualize_reconstruction(\n",
    "        model, val_segments[idx], device,\n",
    "        patch_size=config['model']['patch_size'],\n",
    "        save_path=os.path.join(PROJECT_DIR, f'reconstruction_{i}.png')\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"\\nâœ“ Pre-training complete!\")\n",
    "print(f\"  Best model saved to: {PRETRAIN_SAVE_DIR}/best_model.pt\")\n",
    "print(f\"  Proceed to Notebook 04 for fine-tuning!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
